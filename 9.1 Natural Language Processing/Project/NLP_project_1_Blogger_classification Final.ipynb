{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYgIK5ykp_uF"
   },
   "source": [
    "# DOMAIN: Digital content management\n",
    "## CONTEXT: \n",
    "Classification is probably the most popular task that you would deal with in real life. Text in the form of blogs, posts, articles, etc. is written every second. It is a challenge to predict the information about the writer without knowing about him/her. We are going to create a classifier that predicts multiple features of the author of a given text. We have designed it as a Multi label classification problem.\n",
    "\n",
    "### DATA DESCRIPTION: \n",
    "Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a blogger id# and the blogger’s self-provided gender, age, industry, and astrological sign. (All are labelled for gender and age but for many, industry and/or sign is marked as unknown.) All bloggers included in the corpus fall into one of three age groups:\n",
    "\n",
    "• 8240 \"10s\" blogs (ages 13-17),\n",
    "\n",
    "• 8086 \"20s\" blogs(ages 23-27) and\n",
    "\n",
    "• 2994 \"30s\" blogs (ages 33-47)\n",
    "\n",
    "For each age group, there is an equal number of male and female bloggers.\n",
    "Each blog in the corpus includes at least 200 occurrences of common English words. All formatting has been stripped with two exceptions.\n",
    "Individual posts within a single blogger are separated by the date of the following post and links within a post are denoted by the label url\n",
    "link. Link to dataset: https://www.kaggle.com/rtatman/blog-authorship-corpus\n",
    "\n",
    "## PROJECT OBJECTIVE: \n",
    "The need is to build a NLP classifier which can use input text parameters to determine the label/s of of the blog.\n",
    "## Steps and tasks: [ Total Score: 20 points]\n",
    "1. Import and analyse the data set.\n",
    "2. Perform data pre-processing on the data:\n",
    "\n",
    "*   Data cleansing by removing unwanted characters, spaces, stop words etc. Convert text to lowercase.\n",
    "*   Target/label merger and transformation\n",
    "*   Train and test split\n",
    "*   Vectorisation, etc.\n",
    "\n",
    "3. Design, train, tune and test the best text classifier.\n",
    "4. Display and explain detail the classification report\n",
    "5. Print the true vs predicted labels for any 5 entries from the dataset.\n",
    "\n",
    "* Hint: The aim here Is to import the text, process it such a way that it can be taken as an inout to the ML/NN classifiers. Be analytical and experimental here in trying new approaches to design the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "qbG7qPDprO5Y"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6tHr-ZPTsq1",
    "outputId": "82184caa-bd16-45f5-fd27-498e3a378f0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-10.1/nvvm/libdevice\n",
      "/usr/local/cuda-10.0/nvvm/libdevice\n",
      "/usr/local/cuda-11.0/nvvm/libdevice\n",
      "/usr/local/cuda-10.1/nvvm/lib64/libnvvm.so\n",
      "/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\n",
      "/usr/local/cuda-11.0/nvvm/lib64/libnvvm.so\n"
     ]
    }
   ],
   "source": [
    "!find / -iname 'libdevice'\n",
    "!find / -iname 'libnvvm.so'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "UShDgUe7T3ml"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/cuda-11.0/nvvm/libdevice\"\n",
    "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-11.0/nvvm/lib64/libnvvm.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "qQ6jhpdPU1Nf"
   },
   "outputs": [],
   "source": [
    "from numba import vectorize \n",
    "from numba import jit, cuda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQwb9YUY7dcW",
    "outputId": "47687c73-89bb-44a3-8751-b665292df65f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Enable GPU in the Colab settings for running the code faster\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l1rizCgIso3y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0bbLAscC9n1C"
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XLSGlPBVszkP"
   },
   "outputs": [],
   "source": [
    "import textblob as TextBlob\n",
    "import spacy\n",
    "import wordcloud as WordCloud\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fc3_m_azIJmL"
   },
   "source": [
    "# 1. Import and analyse the data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wqvfCUXls7qY",
    "outputId": "f83095d9-d08b-4217-d1be-2aaa27000b62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pFlzg_jluMX6"
   },
   "outputs": [],
   "source": [
    "project_path = '/content/drive/MyDrive/Colab/NLP/Project1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "DqqdHC5ctCU5",
    "outputId": "ec8efed0-8a53-45c3-9fff-6b612add21ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  ...                                               text\n",
       "0  2059027  ...             Info has been found (+/- 100 pages,...\n",
       "1  2059027  ...             These are the team members:   Drewe...\n",
       "2  2059027  ...             In het kader van kernfusie op aarde...\n",
       "3  2059027  ...                   testing!!!  testing!!!          \n",
       "4  3581210  ...               Thanks to Yahoo!'s Toolbar I can ...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(project_path + 'blogtext.csv', index_col=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVGMQ4KjuWGl",
    "outputId": "d8336238-69fd-4f20-9015-37e20841cc99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681284, 7)"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUPkel_9vkUg",
    "outputId": "9900f15a-aeec-4c04-b09b-d9788ac037f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "gender    object\n",
       "age        int64\n",
       "topic     object\n",
       "sign      object\n",
       "date      object\n",
       "text      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Ubj2gRSvnmN",
    "outputId": "bf3f2602-3cd6-4b74-c1ff-787d4d866a14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 681284 entries, 0 to 681283\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      681284 non-null  int64 \n",
      " 1   gender  681284 non-null  object\n",
      " 2   age     681284 non-null  int64 \n",
      " 3   topic   681284 non-null  object\n",
      " 4   sign    681284 non-null  object\n",
      " 5   date    681284 non-null  object\n",
      " 6   text    681284 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 36.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qeOJ5zCS_4o0",
    "outputId": "31b2446e-ee09-48c5-94f8-4d944d774c33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50000 entries, 25639 to 266424\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      50000 non-null  int64 \n",
      " 1   gender  50000 non-null  object\n",
      " 2   age     50000 non-null  int64 \n",
      " 3   topic   50000 non-null  object\n",
      " 4   sign    50000 non-null  object\n",
      " 5   date    50000 non-null  object\n",
      " 6   text    50000 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Taking a smaller sample data for initial analysis\n",
    "df = df.sample(50000, random_state=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bR9SiOJTITZa"
   },
   "source": [
    "# 2. Perform data pre-processing on the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "Gwtxeb1AASLj",
    "outputId": "731744a9-477c-4dc2-af78-a866ae8de6d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25639</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>Let's say you have friends that hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216060</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>Was officially the COOLEST FUCKING ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633204</th>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>Apparently, a few people consider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582291</th>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aries</td>\n",
       "      <td>His nose is too big for his face.  Eyes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366878</th>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>urlLink     urlLink 16-feb-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gender  age  ...    sign                                               text\n",
       "25639     male   33  ...  Pisces             Let's say you have friends that hav...\n",
       "216060    male   15  ...   Aries             Was officially the COOLEST FUCKING ...\n",
       "633204    male   17  ...  Gemini               Apparently, a few people consider...\n",
       "582291    male   27  ...   Aries         His nose is too big for his face.  Eyes...\n",
       "366878  female   27  ...  Gemini              urlLink     urlLink 16-feb-04        \n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['id', 'date'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "UWz6kbvoAh-v",
    "outputId": "4c815620-a398-4a7c-b440-d650f20e129c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25639</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>Let's say you have friends that hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216060</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>Was officially the COOLEST FUCKING ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633204</th>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>Apparently, a few people consider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582291</th>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aries</td>\n",
       "      <td>His nose is too big for his face.  Eyes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366878</th>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>urlLink     urlLink 16-feb-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gender  age  ...    sign                                               text\n",
       "25639     male   33  ...  Pisces             Let's say you have friends that hav...\n",
       "216060    male   15  ...   Aries             Was officially the COOLEST FUCKING ...\n",
       "633204    male   17  ...  Gemini               Apparently, a few people consider...\n",
       "582291    male   27  ...   Aries         His nose is too big for his face.  Eyes...\n",
       "366878  female   27  ...  Gemini              urlLink     urlLink 16-feb-04        \n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlINVSfvCLRZ"
   },
   "source": [
    "## Data preprocessing:\n",
    "Data cleansing by removing unwanted characters, spaces, stop words etc. Convert text to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3RexW3KBPWp",
    "outputId": "7c0b12b6-cadc-4555-abe1-9a02c5d15f1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "w-r13Vc2CNN_"
   },
   "outputs": [],
   "source": [
    "#@jit(target='cuda')\n",
    "def process_data(text):\n",
    "  # Remove unwanted characters, only keeping alphabetic words\n",
    "  alpha_text = re.sub(r'[^A-Za-z]+',' ', text )\n",
    "  # Convert to lower text\n",
    "  lower_text = alpha_text.lower()\n",
    "  # Remove Stop words \n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  text_wo_sw = ' '.join([words for words in lower_text.split() if words not in stop_words])\n",
    "  # Lemmetization\n",
    "  lemma = WordNetLemmatizer()\n",
    "  processed_text = [lemma.lemmatize(word) for word in text_wo_sw]\n",
    "  processed_text = \"\".join(processed_text)\n",
    "  return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IuvsLc0w5cWM",
    "outputId": "38a6168e-ea0c-492b-ca99-6d0ca69d325a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info found pages urllink urllink feb\n"
     ]
    }
   ],
   "source": [
    "# Check how the process_data function words on a smaller text\n",
    "t = \"Info has been found (+/- 100 pages,. urlLink urlLink 16-feb-04\"\n",
    "t1 = process_data(t)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "uWkLHoYdBK9r",
    "outputId": "6a387c34-58b2-4820-9261-de7ccfaf0de1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25639</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>Let's say you have friends that hav...</td>\n",
       "      <td>let say friends stood past return always good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216060</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>Was officially the COOLEST FUCKING ...</td>\n",
       "      <td>officially coolest fucking day ever blake brot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633204</th>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>Apparently, a few people consider...</td>\n",
       "      <td>apparently people considered cory gang massive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582291</th>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aries</td>\n",
       "      <td>His nose is too big for his face.  Eyes...</td>\n",
       "      <td>nose big face eyes soft little browns intimate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366878</th>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>urlLink     urlLink 16-feb-04</td>\n",
       "      <td>urllink urllink feb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gender  ...                                     processed_text\n",
       "25639     male  ...  let say friends stood past return always good ...\n",
       "216060    male  ...  officially coolest fucking day ever blake brot...\n",
       "633204    male  ...  apparently people considered cory gang massive...\n",
       "582291    male  ...  nose big face eyes soft little browns intimate...\n",
       "366878  female  ...                                urllink urllink feb\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once above step is successful, run apply the function on the full dataset\n",
    "df['processed_text'] = df.text.apply(process_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gelNkw2zz2k0"
   },
   "source": [
    "## Target/label merger and transformation\n",
    "\n",
    "As there are multiple claseses gender, age, topic and sign, we will merge them into a single label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "m3wlZepdz4bQ",
    "outputId": "eab0c58a-0d18-460c-c0df-f50ba49f09cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25639</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Pisces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216060</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633204</th>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Gemini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582291</th>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366878</th>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Gemini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gender  age       topic    sign\n",
       "25639     male   33      indUnk  Pisces\n",
       "216060    male   15  Technology   Aries\n",
       "633204    male   17     Student  Gemini\n",
       "582291    male   27      indUnk   Aries\n",
       "366878  female   27      indUnk  Gemini"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = df[['gender', 'age', 'topic', 'sign']]\n",
    "all_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OUq9YAvO0YSv",
    "outputId": "ad9d86bc-41be-4ef5-98eb-444670896cd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender    object\n",
       "age        int64\n",
       "topic     object\n",
       "sign      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyKne8Ex0chg",
    "outputId": "25078d73-a7aa-46c2-d3f1-7a742c40bf13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender    object\n",
       "age       object\n",
       "topic     object\n",
       "sign      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age is int64, so lets convert it into string\n",
    "all_labels['age'] = all_labels['age'].astype('str')\n",
    "all_labels.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fF59q_p407SQ",
    "outputId": "04706194-9986-4238-bd66-0ee5a7e0850f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 4)"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "xic5-CBh0ne4"
   },
   "outputs": [],
   "source": [
    "m = []\n",
    "for i in range(all_labels.shape[0]):\n",
    "  g = []\n",
    "  for j in range(all_labels.shape[1]):\n",
    "    g.append(all_labels.iloc[i][j])\n",
    "  m.append(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "2XkJlF5k1LC2"
   },
   "outputs": [],
   "source": [
    "df['labels'] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "l_hjqtFq1PNC",
    "outputId": "97c00be3-53b4-4a1a-b328-dfbb330515c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25639</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>Let's say you have friends that hav...</td>\n",
       "      <td>let say friends stood past return always good ...</td>\n",
       "      <td>[male, 33, indUnk, Pisces]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216060</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>Was officially the COOLEST FUCKING ...</td>\n",
       "      <td>officially coolest fucking day ever blake brot...</td>\n",
       "      <td>[male, 15, Technology, Aries]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633204</th>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>Apparently, a few people consider...</td>\n",
       "      <td>apparently people considered cory gang massive...</td>\n",
       "      <td>[male, 17, Student, Gemini]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582291</th>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aries</td>\n",
       "      <td>His nose is too big for his face.  Eyes...</td>\n",
       "      <td>nose big face eyes soft little browns intimate...</td>\n",
       "      <td>[male, 27, indUnk, Aries]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366878</th>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>urlLink     urlLink 16-feb-04</td>\n",
       "      <td>urllink urllink feb</td>\n",
       "      <td>[female, 27, indUnk, Gemini]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gender  ...                         labels\n",
       "25639     male  ...     [male, 33, indUnk, Pisces]\n",
       "216060    male  ...  [male, 15, Technology, Aries]\n",
       "633204    male  ...    [male, 17, Student, Gemini]\n",
       "582291    male  ...      [male, 27, indUnk, Aries]\n",
       "366878  female  ...   [female, 27, indUnk, Gemini]\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "yuB_GJ_s1QeG",
    "outputId": "935c3a34-7af2-4b82-aad3-1426daa2975f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395438</th>\n",
       "      <td>got home picking kids checked phone messages o...</td>\n",
       "      <td>[female, 33, indUnk, Scorpio]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253710</th>\n",
       "      <td>professionally totally urllink stressed trying...</td>\n",
       "      <td>[female, 25, indUnk, Sagittarius]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614190</th>\n",
       "      <td>yesh got spot blogspot pun intended hm wait co...</td>\n",
       "      <td>[male, 16, Engineering, Libra]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426766</th>\n",
       "      <td>hot pants got hot pants</td>\n",
       "      <td>[female, 24, Arts, Libra]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420790</th>\n",
       "      <td>urllink protect personal info</td>\n",
       "      <td>[female, 24, Student, Libra]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           processed_text                             labels\n",
       "395438  got home picking kids checked phone messages o...      [female, 33, indUnk, Scorpio]\n",
       "253710  professionally totally urllink stressed trying...  [female, 25, indUnk, Sagittarius]\n",
       "614190  yesh got spot blogspot pun intended hm wait co...     [male, 16, Engineering, Libra]\n",
       "426766                            hot pants got hot pants          [female, 24, Arts, Libra]\n",
       "420790                      urllink protect personal info       [female, 24, Student, Libra]"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with processed_text and the labels only\n",
    "new_df = df[['processed_text', 'labels']]\n",
    "new_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tQssa5l1kaI",
    "outputId": "c343a4ad-8197-4635-cdc8-19aa59e5247f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['male', '34', 'indUnk', 'Aries']           335\n",
       "['female', '16', 'Student', 'Libra']        272\n",
       "['female', '16', 'Student', 'Aries']        265\n",
       "['female', '23', 'indUnk', 'Aries']         262\n",
       "['female', '26', 'indUnk', 'Cancer']        250\n",
       "                                           ... \n",
       "['female', '33', 'Banking', 'Cancer']         1\n",
       "['female', '26', 'Accounting', 'Gemini']      1\n",
       "['female', '26', 'Fashion', 'Pisces']         1\n",
       "['male', '39', 'Internet', 'Aquarius']        1\n",
       "['male', '35', 'indUnk', 'Leo']               1\n",
       "Name: labels, Length: 3740, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for most frequent bloggers\n",
    "new_df.labels.astype('str').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8tApNil1x3P",
    "outputId": "0f2acbf2-fbb8-4fe0-e36d-6ccc9cd8c8bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "processed_text    0\n",
       "labels            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "new_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jThMq-hE2LaN"
   },
   "source": [
    "## Train and test split\n",
    "First separate the data in X and y and then do a train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "Bep26Rf_2QAa"
   },
   "outputs": [],
   "source": [
    "X = new_df['processed_text']\n",
    "y = new_df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IF_iK76o2Xmz",
    "outputId": "a1d7ccdf-f394-409f-eaaf-bb6f253000cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,) (50000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "cDw5_G_f2Z19"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dx3atEiX2p6s",
    "outputId": "a46ec5c7-e510-4fb6-ba94-bce8a579f181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000,) (35000,) (15000,) (15000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzd_5zh_2yiR"
   },
   "source": [
    "#### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "iMV_jzmK20Bu"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "44fr2CkOSqyL"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2), binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0WDRUpiTZCh",
    "outputId": "aa470dc1-6315-4f5d-8b87-17970cc95afb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<35000x2230871 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6038756 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJIddWC4Tn_e",
    "outputId": "42fceade-c926-4f2c-9d6c-a25a2e9c5397"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aa aa',\n",
       " 'aa aaa',\n",
       " 'aa aaaa',\n",
       " 'aa aaaaa',\n",
       " 'aa aaaaaa',\n",
       " 'aa aaaaaaa',\n",
       " 'aa aaaaaaaa',\n",
       " 'aa aaaaaaaaa',\n",
       " 'aa aaaaaaaaaaaa']"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qn19b36zT42N",
    "outputId": "8e458a13-ddbb-452b-89bc-369242688ebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 302028)\t1\n",
      "  (0, 134140)\t1\n",
      "  (0, 1793634)\t1\n",
      "  (0, 1740066)\t1\n",
      "  (0, 1979318)\t1\n",
      "  (0, 1356137)\t1\n",
      "  (0, 2171836)\t1\n",
      "  (0, 2227169)\t1\n",
      "  (0, 1653204)\t1\n",
      "  (0, 1150089)\t1\n",
      "  (0, 888211)\t1\n",
      "  (0, 1125477)\t1\n",
      "  (0, 1971384)\t1\n",
      "  (0, 1749840)\t1\n",
      "  (0, 1915272)\t1\n",
      "  (0, 57182)\t1\n",
      "  (0, 1325152)\t1\n",
      "  (0, 669806)\t1\n",
      "  (0, 1785274)\t1\n",
      "  (0, 1141122)\t1\n",
      "  (0, 1271649)\t1\n",
      "  (0, 449003)\t1\n",
      "  (0, 1726989)\t1\n",
      "  (0, 1981710)\t1\n",
      "  (0, 1284698)\t1\n",
      "  :\t:\n",
      "  (1, 54944)\t1\n",
      "  (1, 1832435)\t1\n",
      "  (1, 63090)\t1\n",
      "  (1, 744667)\t1\n",
      "  (2, 1971384)\t1\n",
      "  (2, 2061775)\t1\n",
      "  (2, 2193773)\t1\n",
      "  (2, 2114587)\t1\n",
      "  (2, 1948708)\t1\n",
      "  (2, 1221823)\t1\n",
      "  (2, 733824)\t1\n",
      "  (2, 1192394)\t1\n",
      "  (2, 1203022)\t1\n",
      "  (2, 435811)\t1\n",
      "  (2, 768721)\t1\n",
      "  (2, 2115245)\t1\n",
      "  (2, 2068555)\t1\n",
      "  (2, 1952831)\t1\n",
      "  (2, 2195564)\t1\n",
      "  (2, 1221855)\t1\n",
      "  (2, 735475)\t1\n",
      "  (2, 1973953)\t1\n",
      "  (2, 1193495)\t1\n",
      "  (2, 1203209)\t1\n",
      "  (2, 436032)\t1 ['aa', 'aa aa', 'aa aaa']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vect[:3], vectorizer.get_feature_names()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "ZQ80CgrYVNBt",
    "outputId": "60f0e200-fdeb-4389-def3-76c24e1db065"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25639</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Pisces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216060</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633204</th>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Gemini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582291</th>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366878</th>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Gemini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gender age       topic    sign\n",
       "25639     male  33      indUnk  Pisces\n",
       "216060    male  15  Technology   Aries\n",
       "633204    male  17     Student  Gemini\n",
       "582291    male  27      indUnk   Aries\n",
       "366878  female  27      indUnk  Gemini"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the dataframe that we created earlier to create the dictionary of words and their counts\n",
    "all_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "RWY7zzOJagRL"
   },
   "outputs": [],
   "source": [
    "keys = []\n",
    "values = []\n",
    "for i in range(all_labels.shape[1]):\n",
    "  col = all_labels.iloc[:, i].value_counts()\n",
    "  for j in range(col.shape[0]):\n",
    "    keys.append(col.index[j])\n",
    "    values.append(col.iloc[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VX05LBDnbqrZ",
    "outputId": "205ebd89-b8f6-45c6-fbd0-7fe9a6c67be4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education 2151\n"
     ]
    }
   ],
   "source": [
    "# Check a sample key value pair\n",
    "i = 32\n",
    "print(keys[i], values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "Ze0ZXQXGbsHh"
   },
   "outputs": [],
   "source": [
    "dictionary = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPHK82eqdZHT"
   },
   "source": [
    "### Convert the labels using MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "c-2KI87-dLqy"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "tBUJrUzUdftw"
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes=sorted(dictionary.keys()))\n",
    "y_train_mlb = mlb.fit_transform(y_train)\n",
    "y_test_mlb = mlb.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3vZ89cNd2C4",
    "outputId": "17d5b7d5-5435-43c1-f846-61d6dbb3dfcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_mlb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JVVGcRmPd6V-",
    "outputId": "4fa902b8-c875-4f49-d536-007052877a56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_mlb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ndi1WAEVeCJd",
    "outputId": "0a136ebb-b5ae-49f6-e207-f0096026d13e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['male', '26', 'Law', 'Capricorn']"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To verify the binary label transormation lets check 1 value\n",
    "y_train.iloc[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mo-_kv2HeIEk",
    "outputId": "cd6c7cbf-38a9-4477-d53f-b1c75bebb0ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('26', 'Capricorn', 'Law', 'male')"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And its inverse transformed value\n",
    "mlb.inverse_transform(y_train_mlb)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOAIr2PzehXG"
   },
   "source": [
    "# 3. Design, train, tune and test the best text classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZwTKzrYe7Rz",
    "outputId": "1435533d-54dc-429d-9dc0-f2bab3cf072e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 2230871) (35000, 80) (15000, 2230871) (15000, 80)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vect.shape, y_train_mlb.shape, X_test_vect.shape, y_test_mlb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0qdZwdD0fWI5",
    "outputId": "aa0011f8-bd3e-4662-efa3-8c924a9d1119"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "logit = LogisticRegression(solver='lbfgs')\n",
    "ovr = OneVsRestClassifier(logit)\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "  ovr.fit(X_train_vect, y_train_mlb)\n",
    "y_pred_logit = ovr.predict(X_test_vect)\n",
    "y_pred_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2E3N6lxrh0XG"
   },
   "source": [
    "# 4. Display and explain detail the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKlsOkSaiCcB",
    "outputId": "ae1a5b44-a3dd-47b6-ff22-7e2598007920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.02      0.04       285\n",
      "           1       0.48      0.05      0.10       613\n",
      "           2       0.34      0.04      0.07       937\n",
      "           3       0.47      0.08      0.14      1584\n",
      "           4       0.46      0.09      0.14      1796\n",
      "           5       0.27      0.02      0.04      1579\n",
      "           6       0.37      0.03      0.06      1743\n",
      "           7       0.30      0.02      0.05      1494\n",
      "           8       0.34      0.01      0.02      1242\n",
      "           9       0.35      0.02      0.04       997\n",
      "          10       0.17      0.00      0.00       419\n",
      "          11       0.58      0.03      0.06       486\n",
      "          12       0.50      0.02      0.03       366\n",
      "          13       0.25      0.00      0.01       292\n",
      "          14       0.94      0.07      0.14       201\n",
      "          15       1.00      0.04      0.07       159\n",
      "          16       0.00      0.00      0.00        97\n",
      "          17       0.89      0.13      0.23       128\n",
      "          18       0.00      0.00      0.00        73\n",
      "          19       0.00      0.00      0.00        72\n",
      "          20       0.00      0.00      0.00        91\n",
      "          21       0.00      0.00      0.00        49\n",
      "          22       0.00      0.00      0.00        92\n",
      "          23       0.50      0.07      0.12        72\n",
      "          24       0.00      0.00      0.00        50\n",
      "          25       1.00      0.02      0.05        83\n",
      "          26       0.64      0.07      0.13        94\n",
      "          27       0.00      0.00      0.00       117\n",
      "          28       0.00      0.00      0.00        31\n",
      "          29       0.24      0.01      0.02      1075\n",
      "          30       0.00      0.00      0.00        28\n",
      "          31       0.23      0.01      0.02      1449\n",
      "          32       0.43      0.02      0.03       784\n",
      "          33       0.00      0.00      0.00        27\n",
      "          34       0.00      0.00      0.00        80\n",
      "          35       0.00      0.00      0.00        50\n",
      "          36       0.00      0.00      0.00        93\n",
      "          37       0.50      0.04      0.07      1405\n",
      "          38       0.27      0.01      0.01      1084\n",
      "          39       0.00      0.00      0.00        78\n",
      "          40       0.43      0.01      0.01       447\n",
      "          41       0.00      0.00      0.00        23\n",
      "          42       0.00      0.00      0.00       118\n",
      "          43       0.71      0.02      0.04       648\n",
      "          44       0.00      0.00      0.00       237\n",
      "          45       0.00      0.00      0.00        16\n",
      "          46       1.00      0.02      0.03       128\n",
      "          47       0.31      0.01      0.02      1150\n",
      "          48       0.00      0.00      0.00       137\n",
      "          49       0.00      0.00      0.00        78\n",
      "          50       0.33      0.01      0.02       358\n",
      "          51       0.00      0.00      0.00        27\n",
      "          52       0.00      0.00      0.00       207\n",
      "          53       0.00      0.00      0.00        50\n",
      "          54       0.40      0.02      0.03      1204\n",
      "          55       0.33      0.02      0.03      1381\n",
      "          56       0.00      0.00      0.00        46\n",
      "          57       0.00      0.00      0.00         8\n",
      "          58       0.00      0.00      0.00       101\n",
      "          59       0.00      0.00      0.00        70\n",
      "          60       0.00      0.00      0.00        67\n",
      "          61       0.33      0.01      0.02       317\n",
      "          62       0.40      0.02      0.04      1166\n",
      "          63       0.00      0.00      0.00       166\n",
      "          64       0.00      0.00      0.00        62\n",
      "          65       0.14      0.01      0.02       124\n",
      "          66       0.42      0.01      0.03      1164\n",
      "          67       0.00      0.00      0.00       157\n",
      "          68       0.18      0.01      0.01      1256\n",
      "          69       0.00      0.00      0.00        58\n",
      "          70       0.48      0.20      0.28      3443\n",
      "          71       0.24      0.01      0.02      1410\n",
      "          72       0.42      0.03      0.05       888\n",
      "          73       0.00      0.00      0.00        75\n",
      "          74       0.00      0.00      0.00        54\n",
      "          75       1.00      0.09      0.16        57\n",
      "          76       0.29      0.01      0.02      1256\n",
      "          77       0.66      0.63      0.64      7420\n",
      "          78       0.46      0.27      0.34      5451\n",
      "          79       0.65      0.68      0.66      7580\n",
      "\n",
      "   micro avg       0.59      0.21      0.31     60000\n",
      "   macro avg       0.27      0.04      0.05     60000\n",
      "weighted avg       0.44      0.21      0.24     60000\n",
      " samples avg       0.61      0.21      0.30     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_mlb, y_pred_logit ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUz9Ip7vHQLH"
   },
   "source": [
    "# 5. Print the true vs predicted labels for any 5 entries from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "8uhoAvuzHTxs"
   },
   "outputs": [],
   "source": [
    "#sample_pred = y_pred[:5]\n",
    "sample_pred = y_pred_logit[:5]\n",
    "actual_label = y_test_mlb[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "JHjKNSWZHtUX"
   },
   "outputs": [],
   "source": [
    "actual_label = mlb.inverse_transform(actual_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJtQS4NNHz-4",
    "outputId": "b3a2e44b-7518-4aae-da61-1169d59cb2ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('33', 'Aries', 'female', 'indUnk'),\n",
       " ('27', 'Libra', 'indUnk', 'male'),\n",
       " ('35', 'Libra', 'Technology', 'male'),\n",
       " ('17', 'Cancer', 'indUnk', 'male'),\n",
       " ('17', 'Gemini', 'indUnk', 'male')]"
      ]
     },
     "execution_count": 118,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOIUqJG5H2dx",
    "outputId": "b3b70d9e-9aee-47ec-8544-589d1421cee7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('male',), ('indUnk', 'male'), ('male',), ('16', 'male'), ('indUnk', 'male')]"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_pred = mlb.inverse_transform(sample_pred)\n",
    "sample_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JELGX55DH8D8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRsuXUIzAZ4U"
   },
   "source": [
    "# DOMAIN: Customer support\n",
    "## CONTEXT: \n",
    "Great Learning has a an academic support department which receives numerous support requests every day throughout the year. Teams are spread across geographies and try to provide support round the year. Sometimes there are circumstances where due to heavy workload certain request resolutions are delayed, impacting company’s business. Some of the requests are very generic where a proper resolution procedure delivered to the user can solve the problem. Company is looking forward to design an automation which can\n",
    "interact with the user, understand the problem and display the resolution procedure [ if found as a generic request ] or redirect the request\n",
    "to an actual human support executive if the request is complex or not in it’s database.\n",
    "## DATA DESCRIPTION: \n",
    "A sample corpus is attached for your reference. Please enhance/add more data to the corpus using your linguistics skills.\n",
    "# PROJECT OBJECTIVE: \n",
    "Design a python based interactive semi - rule based chatbot which can do the following:\n",
    "1. Start chat session with greetings and ask what the user is looking for.\n",
    "2. Accept dynamic text based questions from the user. Reply back with relevant answer from the designed corpus.\n",
    "3. End the chat session only if the user requests to end else ask what the user is looking for. Loop continues till the user asks to end it.\n",
    "\n",
    "Please use the sample chatbot demo video for reference.\n",
    "\n",
    "## EVALUATION: \n",
    "GL evaluator will use linguistics to twist and turn sentences to ask questions on the topics described in DATA DESCRIPTION and check if the bot is giving relevant replies.\n",
    "\n",
    "### Hint: \n",
    "There are a lot of techniques using which one can clean and prepare the data which can be used to train a ML/DL classifier. Hence, it might require you to experiment, research, self learn and implement the above classifier. There might be many iterations between hand building the corpus and designing the best fit text classifier. As the quality and quantity of corpus increases the model’s performance i.e. ability to answer right questions also increases.\n",
    "\n",
    "#### Reference: https://www.mygreatlearning.com/blog/basics-of-building-an-artificial-intelligence-chatbot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uBaNFiMAzBF",
    "outputId": "c9eda798-e483-462a-a61a-32bf9f8a0783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'Intro', 'patterns': ['hi', 'how are you', 'is anyone there', 'hello', 'whats up', 'hey', 'yo', 'listen', 'please help me', 'i am learner from', 'i belong to', 'aiml batch', 'aifl batch', 'i am from', 'my pm is', 'blended', 'online', 'i am from', 'hey ya', 'talking to you for first time'], 'responses': ['Hello! how can i help you ?'], 'context_set': ''}, {'tag': 'Exit', 'patterns': ['thank you', 'thanks', 'cya', 'see you', 'later', 'see you later', 'goodbye', 'i am leaving', 'have a Good day', 'you helped me', 'thanks a lot', 'thanks a ton', 'you are the best', 'great help', 'too good', 'you are a good learning buddy'], 'responses': ['I hope I was able to assist you, Good Bye'], 'context_set': ''}, {'tag': 'Olympus', 'patterns': ['olympus', 'explain me how olympus works', 'I am not able to understand olympus', 'olympus window not working', 'no access to olympus', 'unable to see link in olympus', 'no link visible on olympus', 'whom to contact for olympus', 'lot of problem with olympus', 'olypus is not a good tool', 'lot of problems with olympus', 'how to use olympus', 'teach me olympus'], 'responses': ['Link: Olympus wiki'], 'context_set': ''}, {'tag': 'SL', 'patterns': ['i am not able to understand svm', 'explain me how machine learning works', 'i am not able to understand naive bayes', 'i am not able to understand logistic regression', 'i am not able to understand ensemble techb=niques', 'i am not able to understand knn', 'i am not able to understand knn imputer', 'i am not able to understand cross validation', 'i am not able to understand boosting', 'i am not able to understand random forest', 'i am not able to understand ada boosting', 'i am not able to understand gradient boosting', 'machine learning', 'ML', 'SL', 'supervised learning', 'knn', 'logistic regression', 'regression', 'classification', 'naive bayes', 'nb', 'ensemble techniques', 'bagging', 'boosting', 'ada boosting', 'ada', 'gradient boosting', 'hyper parameters'], 'responses': ['Link: Machine Learning wiki '], 'context_set': ''}, {'tag': 'NN', 'patterns': ['what is deep learning', 'unable to understand deep learning', 'explain me how deep learning works', 'i am not able to understand deep learning', 'not able to understand neural nets', 'very diffult to understand neural nets', 'unable to understand neural nets', 'ann', 'artificial intelligence', 'artificial neural networks', 'weights', 'activation function', 'hidden layers', 'softmax', 'sigmoid', 'relu', 'otimizer', 'forward propagation', 'backward propagation', 'epochs', 'epoch', 'what is an epoch', 'adam', 'sgd'], 'responses': ['Link: Neural Nets wiki'], 'context_set': ''}, {'tag': 'Bot', 'patterns': ['what is your name', 'who are you', 'name please', 'when are your hours of opertions', 'what are your working hours', 'hours of operation', 'working hours', 'hours'], 'responses': ['I am your virtual learning assistant'], 'context_set': ''}, {'tag': 'Profane', 'patterns': ['what the hell', 'bloody stupid bot', 'do you think you are very smart', 'screw you', 'i hate you', 'you are stupid', 'jerk', 'you are a joke', 'useless piece of shit'], 'responses': ['Please use respectful words'], 'context_set': ''}, {'tag': 'Ticket', 'patterns': ['my problem is not solved', 'you did not help me', 'not a good solution', 'bad solution', 'not good solution', 'no help', 'wasted my time', 'useless bot', 'create a ticket'], 'responses': ['Tarnsferring the request to your PM'], 'context_set': ''}]}\n"
     ]
    }
   ],
   "source": [
    "# Importing Corpus GL Bot\n",
    "import json\n",
    "\n",
    "with open(project_path + 'GL Bot.json') as file:\n",
    "  corpus = json.load(file)\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PQVhJKvRBq5",
    "outputId": "75d25ee1-794f-4dc2-c216-ebf9be386e14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Extract data\n",
    "# Tokens\n",
    "W = []\n",
    "\n",
    "# tags\n",
    "L = []\n",
    "\n",
    "#Tokenized words\n",
    "X = []\n",
    "\n",
    "#Tags\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "hX037sfvRk_g"
   },
   "outputs": [],
   "source": [
    "for intent in corpus['intents']:\n",
    "  for pattern in intent['patterns']:\n",
    "    w_tmp = nltk.word_tokenize(pattern)\n",
    "    W.extend(w_tmp)\n",
    "    X.append(w_tmp)\n",
    "    y.append(intent['tag'])\n",
    "  \n",
    "  if (intent['tag'] not in L):\n",
    "    L.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zh5kI-lfSUYE",
    "outputId": "bee5d89a-5f3f-49e1-c44c-b8bdf13ced5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'how', 'are', 'you', 'is', 'anyone', 'there', 'hello', 'whats', 'up', 'hey', 'yo', 'listen', 'please', 'help', 'me', 'i', 'am', 'learner', 'from', 'i', 'belong', 'to', 'aiml', 'batch', 'aifl', 'batch', 'i', 'am', 'from', 'my', 'pm', 'is', 'blended', 'online', 'i', 'am', 'from', 'hey', 'ya', 'talking', 'to', 'you', 'for', 'first', 'time', 'thank', 'you', 'thanks', 'cya', 'see', 'you', 'later', 'see', 'you', 'later', 'goodbye', 'i', 'am', 'leaving', 'have', 'a', 'Good', 'day', 'you', 'helped', 'me', 'thanks', 'a', 'lot', 'thanks', 'a', 'ton', 'you', 'are', 'the', 'best', 'great', 'help', 'too', 'good', 'you', 'are', 'a', 'good', 'learning', 'buddy', 'olympus', 'explain', 'me', 'how', 'olympus', 'works', 'I', 'am', 'not', 'able', 'to', 'understand', 'olympus', 'olympus', 'window', 'not', 'working', 'no', 'access', 'to', 'olympus', 'unable', 'to', 'see', 'link', 'in', 'olympus', 'no', 'link', 'visible', 'on', 'olympus', 'whom', 'to', 'contact', 'for', 'olympus', 'lot', 'of', 'problem', 'with', 'olympus', 'olypus', 'is', 'not', 'a', 'good', 'tool', 'lot', 'of', 'problems', 'with', 'olympus', 'how', 'to', 'use', 'olympus', 'teach', 'me', 'olympus', 'i', 'am', 'not', 'able', 'to', 'understand', 'svm', 'explain', 'me', 'how', 'machine', 'learning', 'works', 'i', 'am', 'not', 'able', 'to', 'understand', 'naive', 'bayes', 'i', 'am', 'not', 'able', 'to', 'understand', 'logistic', 'regression', 'i', 'am', 'not', 'able', 'to', 'understand', 'ensemble', 'techb=niques', 'i', 'am', 'not', 'able', 'to', 'understand', 'knn', 'i', 'am', 'not', 'able', 'to', 'understand', 'knn', 'imputer', 'i', 'am', 'not', 'able', 'to', 'understand', 'cross', 'validation', 'i', 'am', 'not', 'able', 'to', 'understand', 'boosting', 'i', 'am', 'not', 'able', 'to', 'understand', 'random', 'forest', 'i', 'am', 'not', 'able', 'to', 'understand', 'ada', 'boosting', 'i', 'am', 'not', 'able', 'to', 'understand', 'gradient', 'boosting', 'machine', 'learning', 'ML', 'SL', 'supervised', 'learning', 'knn', 'logistic', 'regression', 'regression', 'classification', 'naive', 'bayes', 'nb', 'ensemble', 'techniques', 'bagging', 'boosting', 'ada', 'boosting', 'ada', 'gradient', 'boosting', 'hyper', 'parameters', 'what', 'is', 'deep', 'learning', 'unable', 'to', 'understand', 'deep', 'learning', 'explain', 'me', 'how', 'deep', 'learning', 'works', 'i', 'am', 'not', 'able', 'to', 'understand', 'deep', 'learning', 'not', 'able', 'to', 'understand', 'neural', 'nets', 'very', 'diffult', 'to', 'understand', 'neural', 'nets', 'unable', 'to', 'understand', 'neural', 'nets', 'ann', 'artificial', 'intelligence', 'artificial', 'neural', 'networks', 'weights', 'activation', 'function', 'hidden', 'layers', 'softmax', 'sigmoid', 'relu', 'otimizer', 'forward', 'propagation', 'backward', 'propagation', 'epochs', 'epoch', 'what', 'is', 'an', 'epoch', 'adam', 'sgd', 'what', 'is', 'your', 'name', 'who', 'are', 'you', 'name', 'please', 'when', 'are', 'your', 'hours', 'of', 'opertions', 'what', 'are', 'your', 'working', 'hours', 'hours', 'of', 'operation', 'working', 'hours', 'hours', 'what', 'the', 'hell', 'bloody', 'stupid', 'bot', 'do', 'you', 'think', 'you', 'are', 'very', 'smart', 'screw', 'you', 'i', 'hate', 'you', 'you', 'are', 'stupid', 'jerk', 'you', 'are', 'a', 'joke', 'useless', 'piece', 'of', 'shit', 'my', 'problem', 'is', 'not', 'solved', 'you', 'did', 'not', 'help', 'me', 'not', 'a', 'good', 'solution', 'bad', 'solution', 'not', 'good', 'solution', 'no', 'help', 'wasted', 'my', 'time', 'useless', 'bot', 'create', 'a', 'ticket']\n"
     ]
    }
   ],
   "source": [
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjT_JNCMbuNO",
    "outputId": "6fab6e54-2794-4262-b183-e3f6d8e71c19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'Bot', 'Bot', 'Bot', 'Bot', 'Bot', 'Bot', 'Bot', 'Bot', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "lJfABCnySxc0"
   },
   "outputs": [],
   "source": [
    "# Stemming\n",
    "stemmer = SnowballStemmer('english')\n",
    "W = [stemmer.stem(w.lower()) for w in W if w != '?']\n",
    "W = sorted(list(set(W)))\n",
    "L = sorted(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BWL1s0rT8QN",
    "outputId": "dbe650f8-b013-4b62-ab42-b5d39ec8dada"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bot', 'Exit', 'Intro', 'NN', 'Olympus', 'Profane', 'SL', 'Ticket']"
      ]
     },
     "execution_count": 185,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJTBlfENT-Cp",
    "outputId": "05fce220-6ee7-47bd-c033-7a984f529b09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 186,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "empty = [0 for _ in range(len(L))]\n",
    "empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "pdmisWFLUU4C"
   },
   "outputs": [],
   "source": [
    "for i, doc in enumerate(X):\n",
    "  bag = []\n",
    "  w_tmp = [stemmer.stem(w.lower()) for w in doc]\n",
    "\n",
    "  for w in W:\n",
    "    if (w in w_tmp):\n",
    "      bag.append(1)\n",
    "    else:\n",
    "      bag.append(0)\n",
    "  out_row = empty[:]\n",
    "  out_row[L.index(y[i])] = 1\n",
    "\n",
    "  X_train.append(bag)\n",
    "  y_train.append(out_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8cCmMvTVGur",
    "outputId": "106bd767-b226-4415-a97a-35b890d9ac71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 128\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJy3F8-YWy1_",
    "outputId": "55ae3740-09c2-4421-d5c8-04fcc4e9cf7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 189,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obT1IHr1VMUR",
    "outputId": "7e40dc8c-ede0-4d34-ea4d-6a1accd9d0b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      " [0, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "j = 2\n",
    "print(X_train[j], '\\n', y_train[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "7QgBwLDnVWn7"
   },
   "outputs": [],
   "source": [
    "# Define a neural Network to train the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "KU4eu-pLWD6w"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(64,  input_dim=(len(X_train[0])), activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(len(y_train[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avajzUECW89E",
    "outputId": "216eea26-6cea-4944-d6bc-fe509941e545"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2260 - accuracy: 0.0979\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2297 - accuracy: 0.1698\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.1279 - accuracy: 0.1510\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.1077 - accuracy: 0.1583\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1952 - accuracy: 0.1812\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3072 - accuracy: 0.1156\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.1252 - accuracy: 0.1948\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3049 - accuracy: 0.1375\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0960 - accuracy: 0.1844\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1590 - accuracy: 0.1146\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1057 - accuracy: 0.1792\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1071 - accuracy: 0.1698\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0951 - accuracy: 0.1510\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1328 - accuracy: 0.2146\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1374 - accuracy: 0.1583\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0429 - accuracy: 0.2344\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0958 - accuracy: 0.1562\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0768 - accuracy: 0.2031\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1089 - accuracy: 0.1573\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0405 - accuracy: 0.2198\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0229 - accuracy: 0.2354\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0530 - accuracy: 0.1958\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0460 - accuracy: 0.1323\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0611 - accuracy: 0.2177\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0130 - accuracy: 0.2156\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0047 - accuracy: 0.2875\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0728 - accuracy: 0.2062\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9940 - accuracy: 0.2302\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0361 - accuracy: 0.2729\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9921 - accuracy: 0.2854\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0104 - accuracy: 0.1802\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0095 - accuracy: 0.2240\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0973 - accuracy: 0.2396\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9791 - accuracy: 0.2177\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0503 - accuracy: 0.2031\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0101 - accuracy: 0.2062\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0183 - accuracy: 0.2646\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0616 - accuracy: 0.1417\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9715 - accuracy: 0.2594\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0122 - accuracy: 0.2448\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9501 - accuracy: 0.2271\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0740 - accuracy: 0.2313\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0182 - accuracy: 0.2469\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9874 - accuracy: 0.2698\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9524 - accuracy: 0.3260\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0209 - accuracy: 0.2333\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9480 - accuracy: 0.3042\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0473 - accuracy: 0.2760\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0002 - accuracy: 0.1969\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9969 - accuracy: 0.1938\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9443 - accuracy: 0.1938\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0146 - accuracy: 0.2646\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9725 - accuracy: 0.2406\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0178 - accuracy: 0.2583\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9568 - accuracy: 0.2313\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9801 - accuracy: 0.2333\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9674 - accuracy: 0.1990\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9699 - accuracy: 0.2677\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0005 - accuracy: 0.3115\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9546 - accuracy: 0.2802\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8915 - accuracy: 0.2646\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9400 - accuracy: 0.3250\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9142 - accuracy: 0.2573\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9649 - accuracy: 0.3052\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9276 - accuracy: 0.1823\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9165 - accuracy: 0.2979\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8623 - accuracy: 0.3094\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9372 - accuracy: 0.2229\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9406 - accuracy: 0.2115\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8798 - accuracy: 0.2667\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9621 - accuracy: 0.2896\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9173 - accuracy: 0.2844\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9063 - accuracy: 0.2948\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9275 - accuracy: 0.2437\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8799 - accuracy: 0.3146\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9021 - accuracy: 0.2594\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9081 - accuracy: 0.2833\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8490 - accuracy: 0.2417\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8571 - accuracy: 0.2833\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9531 - accuracy: 0.2958\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8733 - accuracy: 0.2333\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9585 - accuracy: 0.2219\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8860 - accuracy: 0.2458\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8649 - accuracy: 0.2448\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9338 - accuracy: 0.2437\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8401 - accuracy: 0.3135\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9207 - accuracy: 0.2844\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8058 - accuracy: 0.2990\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8630 - accuracy: 0.2760\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8040 - accuracy: 0.3010\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9043 - accuracy: 0.2458\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8669 - accuracy: 0.3365\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8027 - accuracy: 0.2833\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9053 - accuracy: 0.2792\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.7531 - accuracy: 0.2865\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9013 - accuracy: 0.2458\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.7439 - accuracy: 0.4031\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8634 - accuracy: 0.2458\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.7621 - accuracy: 0.3333\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.7743 - accuracy: 0.3073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f74e3dd0a10>"
      ]
     },
     "execution_count": 230,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=0.001, amsgrad=True )\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "ELrszid9eFGj"
   },
   "outputs": [],
   "source": [
    "for i in range(len(y_train)):\n",
    "  if (len(y_train[i])> 8):\n",
    "    print(len(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "6WKibeEDXN1Q"
   },
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "  if (len(X_train[i])> 154):\n",
    "    print(len(X_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "RQTIilVTIHG_"
   },
   "outputs": [],
   "source": [
    "def bow(input_text):\n",
    "  bag = []\n",
    "  input_tmp = nltk.word_tokenize(input_text)\n",
    "  w_tmp = [stemmer.stem(w.lower()) for w in input_tmp]\n",
    "\n",
    "  for w in W:\n",
    "    if (w in w_tmp):\n",
    "      bag.append(1)\n",
    "    else:\n",
    "      bag.append(0)\n",
    "  out_row = empty[:]\n",
    "  out_row[L.index(y[i])] = 1\n",
    "  return bag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MkQ9YvrjIs3l",
    "outputId": "d836de19-27af-4eb0-f295-8fddd3ce6be3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "test = bow(\"Hi, how are you doing?\")\n",
    "print(test)\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "Oszqc-DmC7yv"
   },
   "outputs": [],
   "source": [
    "# Text chat function\n",
    "import random\n",
    "def chat():\n",
    "  print(\"Chat with Chatbot(type: stop to quit)\")\n",
    "  print('If you are not satisfied by the response: (type *)')\n",
    "  while True:\n",
    "    inp = input(\"\\n\\nYou: \")\n",
    "    if (inp.lower() == \"*\"):\n",
    "      print(\"BOT: Please rephrase your question and try again\")\n",
    "    if (inp.lower() == 'stop'):\n",
    "      break\n",
    "    \n",
    "    #inp = [inp]\n",
    "    print(inp)\n",
    "    token = bow(inp)\n",
    "    print(token)\n",
    "    print(len(token))\n",
    "    results = model.predict([token])\n",
    "    results_index = np.argmax(results)\n",
    "    tag = L[results_index]\n",
    "\n",
    "    for tg in corpus['intents']:\n",
    "      if (tg['tag'] == tag):\n",
    "        responses = tg['responses']\n",
    "\n",
    "    #print(random.choice(responses ))\n",
    "    print(responses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fz0uJJJbKVk",
    "outputId": "27d4a3d0-12fd-49d7-fe00-1da4df3b4f8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat with Chatbot(type: stop to quit)\n",
      "If you are not satisfied by the response: (type *)\n",
      "\n",
      "\n",
      "You: hello\n",
      "hello\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "154\n",
      "['Hello! how can i help you ?']\n",
      "\n",
      "\n",
      "You: olympus\n",
      "olympus\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "154\n",
      "['Link: Olympus wiki']\n",
      "\n",
      "\n",
      "You: i am not able to understand svm\n",
      "i am not able to understand svm\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "154\n",
      "['Link: Machine Learning wiki ']\n",
      "\n",
      "\n",
      "You: what is deep learning\n",
      "what is deep learning\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "154\n",
      "['Link: Neural Nets wiki']\n",
      "\n",
      "\n",
      "You: what is your name\n",
      "what is your name\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "154\n",
      "['Link: Neural Nets wiki']\n",
      "\n",
      "\n",
      "You: who are you\n",
      "who are you\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "154\n",
      "['Link: Neural Nets wiki']\n",
      "\n",
      "\n",
      "You: name please\n",
      "name please\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "154\n",
      "['Link: Neural Nets wiki']\n",
      "\n",
      "\n",
      "You: what the hell\n",
      "what the hell\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "154\n",
      "['Link: Neural Nets wiki']\n",
      "\n",
      "\n",
      "You: you are a joke\n",
      "you are a joke\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "154\n",
      "['Hello! how can i help you ?']\n",
      "\n",
      "\n",
      "You: my problem is not solved\n",
      "my problem is not solved\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "154\n",
      "['Link: Machine Learning wiki ']\n",
      "\n",
      "\n",
      "You: you did not help me\n",
      "you did not help me\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "154\n",
      "['Hello! how can i help you ?']\n",
      "\n",
      "\n",
      "You: create a ticket\n",
      "create a ticket\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "154\n",
      "['Link: Neural Nets wiki']\n",
      "\n",
      "\n",
      "You: stop\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3jIPevmI1J5",
    "outputId": "71b1d98d-c47e-4635-8297-355540cab2e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 64)                9920      \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 14,600\n",
      "Trainable params: 14,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_j9v3qxf5Et"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "NLP project-1 - Blogger classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
